{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-cookbook/blob/main/notebooks/intent_class_synthetic/generating_test_scenarios.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "\n",
    "## Generate Test Scenarios and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from okareo import Okareo\n",
    "from okareo_api_client.models import ScenarioType\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"blog_data/testing.csv\")\n",
    "rows = test_data.to_dict(orient=\"records\")\n",
    "\n",
    "# Write to a .jsonl file\n",
    "temp_dir = tempfile.gettempdir()\n",
    "file_path = os.path.join(temp_dir, \"seed_data_sample.jsonl\")\n",
    "with open(file_path, \"w+\") as file:\n",
    "    for row in rows:\n",
    "        file.write(json.dumps(row) + '\\n')\n",
    "    \n",
    "\n",
    "# Create scenario set with seed data file\n",
    "source_scenario = okareo.upload_scenario_set(file_path=file_path, scenario_name=\"Blog Test Set\")\n",
    "print(source_scenario.app_link)\n",
    "\n",
    "# make sure to clean up tmp file\n",
    "os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Rephrased Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scenario set id or scenario set object from previous step as source for generation\n",
    "rephrased_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - rephrase\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.REPHRASE_INVARIANT\n",
    ")\n",
    "\n",
    "print(rephrased_scenario.app_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Misspellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - spelling\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.COMMON_MISSPELLINGS\n",
    ")\n",
    "\n",
    "print(spelling_scenario.app_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contr_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - contractions\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.COMMON_CONTRACTIONS\n",
    ")\n",
    "\n",
    "print(contr_scenario.app_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Conditional Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - conditional\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.CONDITIONAL\n",
    ")\n",
    "\n",
    "print(cond_scenario.app_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Base model on the synthetic data\n",
    "\n",
    "This will create a classifier evaluation in Okareo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the necessary libraries from Okareo\n",
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "# Load the torch library\n",
    "import torch\n",
    "\n",
    "# Load libraries\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load a tokenizer for the model from the Hugging Face Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load your pretrained model from where it is stored\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"blog_model_base\")\n",
    "\n",
    "# Define a model class that will be used used for classification\n",
    "# The model takes in a scenario and returns a predicted class\n",
    "class ClassificationModel(CustomModel):\n",
    "    # Constructor for the model\n",
    "    def __init__(self, name, tokenizer, model):\n",
    "        self.name = name\n",
    "        # The pretrained tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # The pretrained model\n",
    "        self.model = model\n",
    "        # The possible labels for the model\n",
    "        self.label_lookup = [\"pricing\", \"returns\", \"complaints\"]\n",
    "\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    def invoke(self, input: str):\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(input, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        # Get the logits from the model\n",
    "        logits = self.model(**encoding).logits\n",
    "        # Get the index of the highest value (the predicted class)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        # Get the label for the predicted class\n",
    "        prediction = self.label_lookup[idx]\n",
    "        \n",
    "        # Return the prediction in a ModelInvocation object\n",
    "        return ModelInvocation(\n",
    "                model_prediction=prediction,\n",
    "                model_input=input,\n",
    "                raw_model_output={ \"prediction\": prediction, \"confidence\": logits.softmax(dim=1).max().item() },\n",
    "            )\n",
    "\n",
    "# Register the model with Okareo\n",
    "# This will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test_base = okareo.register_model(name=\"blog_intent_classifier_model_base\", model=ClassificationModel(name=\"Classification model\", tokenizer=tokenizer, model=model), update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=rephrased_scenario.scenario_id, \n",
    "    name=\"Blog - rephrase\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=spelling_scenario.scenario_id, \n",
    "    name=\"Blog - spelling\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=contr_scenario.scenario_id, \n",
    "    name=\"Blog - contractions\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=cond_scenario.scenario_id, \n",
    "    name=\"Blog - conditional\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=source_scenario.scenario_id, \n",
    "    name=\"Blog - base\", \n",
    "    calculate_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same thing with the Synthetic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Okareo's pretrained model from the Hugging Face Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"blog_model_synthetic\")\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Define a model class that will be used used for classification\n",
    "# The model takes in a scenario and returns a predicted class\n",
    "class ClassificationModel(CustomModel):\n",
    "    # Constructor for the model\n",
    "    def __init__(self, name, tokenizer, model):\n",
    "        self.name = name\n",
    "        # The pretrained tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # The pretrained model\n",
    "        self.model = model\n",
    "        # The possible labels for the model\n",
    "        self.label_lookup = [\"pricing\", \"returns\", \"complaints\"]\n",
    "\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    def invoke(self, input: str):\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(input, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        # Get the logits from the model\n",
    "        logits = self.model(**encoding).logits\n",
    "        # Get the index of the highest value (the predicted class)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        # Get the label for the predicted class\n",
    "        prediction = self.label_lookup[idx]\n",
    "        \n",
    "        # Return the prediction in a ModelInvocation object\n",
    "        return ModelInvocation(\n",
    "                model_prediction=prediction,\n",
    "                model_input=input,\n",
    "                raw_model_output={ \"prediction\": prediction, \"confidence\": logits.softmax(dim=1).max().item() },\n",
    "            )\n",
    "\n",
    "# Register the model with Okareo\n",
    "# This will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test_syn = okareo.register_model(name=\"blog_intent_classifier_model_w_synthetic\", model=ClassificationModel(name=\"Classification model\", tokenizer=tokenizer, model=model), update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=rephrased_scenario.scenario_id, \n",
    "    name=\"Blog - syn - rephrase\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=spelling_scenario.scenario_id, \n",
    "    name=\"Blog - syn - spelling\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=contr_scenario.scenario_id, \n",
    "    name=\"Blog - syn - contractions\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=cond_scenario.scenario_id, \n",
    "    name=\"Blog - syn - conditional\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=source_scenario.scenario_id, \n",
    "    name=\"Blog - syn - base\", \n",
    "    calculate_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
