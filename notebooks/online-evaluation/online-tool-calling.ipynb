{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download and install the [Okareo CLI](https://docs.okareo.com/docs/sdk/cli#proxy).\n",
    "\n",
    "Then, run `okareo proxy`. Sending completions to this proxy will allow you to send datapoints to Okareo automatically.\n",
    "\n",
    "When your datapoints are uploaded to Okareo, they will be tagged with a 'task' label. The currently supported tasks are:\n",
    "\n",
    "- Question Answering\n",
    "- Roleplaying \n",
    "- Code Generation\n",
    "- Tool Calling\n",
    "- Data Extraction\n",
    "- Classification\n",
    "- Summarization\n",
    "\n",
    "The task tags allowing you to sort through your data via segments, which are built from user-configurable filters on datapoints.\n",
    "\n",
    "To illustrate datapoints and segments in Okareo, let's set up a model that is tasked with generating tool calls. We expect these datapoints to be labeled with the \"tool calling\" task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai # openai v1.0.0+\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"http://0.0.0.0:4000\", # URL for Okareo proxy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"data/gorilla_tools.jsonl\"\n",
    "\n",
    "gorilla_tools = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        gorilla_tools.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AfDQSH2SXMqKs9NdS3lx0US4tz0Ya', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z8qRWW3RkamW4pZIbaIUCH33', function=Function(arguments='{\"name\":\"report\"}', name='find'), type='function')]))], created=1734386420, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a79d8dac1f', usage=CompletionUsage(completion_tokens=13, prompt_tokens=2049, total_tokens=2062, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1920)))\n"
     ]
    }
   ],
   "source": [
    "system_prompt_template = \"\"\"Given the following initial state, invoke one or more appropriate functions.\n",
    "\n",
    "Initial state:\n",
    "{\n",
    "    'GorillaFileSystem': {\n",
    "        'root': {\n",
    "            'workspace': {\n",
    "                'type': 'directory',\n",
    "                'contents': {\n",
    "                    'document': {\n",
    "                        'type': 'directory',\n",
    "                        'contents': {\n",
    "                            'final_report.pdf': {\n",
    "                                'type': 'file',\n",
    "                                'content': 'Year2024 This is the final report content including budget analysis and other sections.'\n",
    "                            },\n",
    "                            'previous_report.pdf': {\n",
    "                                'type': 'file',\n",
    "                                'content': 'Year203 This is the previous report content with different budget analysis.'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_template},\n",
    "    {\"role\": \"user\", \"content\": \"Recursively find file names containing 'report'\"}\n",
    "]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=messages,\n",
    "    tools=gorilla_tools\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AfDSS1ZCilkXmQA83pu2WqbXbY9RD', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dLJZLG6fJUwnmZsywaKlSmdc', function=Function(arguments='{}', name='du'), type='function')]))], created=1734386544, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a79d8dac1f', usage=CompletionUsage(completion_tokens=9, prompt_tokens=2054, total_tokens=2063, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1920)))\n"
     ]
    }
   ],
   "source": [
    "# generate another datapoint with a different user message\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_template},\n",
    "    {\"role\": \"user\", \"content\": \"List the size of the files/directories in the currect directory.\"}\n",
    "]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=messages,\n",
    "    tools=gorilla_tools\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
