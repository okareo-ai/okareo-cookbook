{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling Evaluation on Gorilla BFCL Dataset\n",
    "\n",
    "**ðŸŽ¯ Goal**:\n",
    "- Run a function calling evaluation in Okareo using the BFCL v3 data.\n",
    "- Provide a simple introduction to Okareo evaluations.\n",
    "\n",
    "**ðŸ“‹ Steps**:\n",
    "1. Upload a function calling scenario using the BFCL data.\n",
    "2. Define a custom model to generate the function calls\n",
    "3. Run the evaluation using the scenario (from #1) + model (from #2) along with Okareo predefined checks to measure function call accuracy, including:\n",
    "    - function_call_validator\n",
    "    - is_function_correct\n",
    "    - are_all_params_expected\n",
    "    - are_required_params_present\n",
    "    - do_param_values_match\n",
    "\n",
    "**Notes**\n",
    "- We use the ['simple' data](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard/blob/main/BFCL_v3_live_simple.json) that consists of a single turn. Other variants with multi-turn conversation histories are also in [this repo](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard/tree/main).\n",
    "- The 'ground truth'/expected results are available in the ['possible answers' directory](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard/tree/main/possible_answer) of the repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get Okareo client\n",
    "from okareo import Okareo\n",
    "\n",
    "OKAREO_API_KEY = os.environ.get(\"OKAREO_API_KEY\")\n",
    "if not OKAREO_API_KEY:\n",
    "    raise ValueError(\"OKAREO_API_KEY environment variable is not set\")\n",
    "okareo = Okareo(OKAREO_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_function_name_safe(text: str) -> str:\n",
    "    return text.replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we would use `datasets` from huggingface to download the data, but there was an issue with the column names.\n",
    "\n",
    "Instead, use the manually downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from huggingface_hub import login\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Authenticate with your Hugging Face API token\n",
    "# HUGGINGFACE_API_TOKEN = os.environ[\"HUGGINGFACE_API_KEY\"]\n",
    "# login(token=HUGGINGFACE_API_TOKEN)\n",
    "\n",
    "# dataset = load_dataset(\"gorilla-llm/Berkeley-Function-Calling-Leaderboard\", split=\"train\")\n",
    "\n",
    "import json\n",
    "\n",
    "input_filename = \"./data/BFCL_v3_live_simple.json\"\n",
    "result_filename = \"./data/possible_answers/BFCL_v3_live_simple.json\"\n",
    "\n",
    "inputs = {}\n",
    "with open(input_filename, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        input_ = json.loads(line)\n",
    "        # make function names safe to use with OpenAI, which  expects only alphanumeric characters, underscores, or hyphens\n",
    "        function_list = []\n",
    "        for f in input_[\"function\"]:\n",
    "            f['name'] = make_function_name_safe(f['name'])\n",
    "            function_list.append(f)\n",
    "        inputs[input_[\"id\"]] = {\"question\": input_[\"question\"], \"function\": function_list}\n",
    "\n",
    "results = {}\n",
    "with open(result_filename, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        result = json.loads(line)\n",
    "        function_list = []\n",
    "        for f in result[\"ground_truth\"]:\n",
    "            f_safe = {make_function_name_safe(k): v for k, v in f.items()}\n",
    "            function_list.append(f_safe)\n",
    "        results[result[\"id\"]] = {\"ground_truth\": function_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_user_info',\n",
       "  'description': 'Retrieve details for a specific user by their unique identifier.',\n",
       "  'parameters': {'type': 'dict',\n",
       "   'required': ['user_id'],\n",
       "   'properties': {'user_id': {'type': 'integer',\n",
       "     'description': 'The unique identifier of the user. It is used to fetch the specific user details from the database.'},\n",
       "    'special': {'type': 'string',\n",
       "     'description': 'Any special information or parameters that need to be considered while fetching user details.',\n",
       "     'default': 'none'}}}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['live_simple_0-0-0']['function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'get_user_info': {'user_id': [7890], 'special': ['black']}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['live_simple_0-0-0']['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The name for a scenario must be unique. The scenario name BFCL Gorilla - Simple Function Call is already in use, and has been returned from this call.\n",
      "http://localhost:3000/project/2765bfd0-f296-4ae6-8ef9-acbfd56dc786/scenario/2edac4a3-4ba2-43ee-a7a6-e6916f238165\n"
     ]
    }
   ],
   "source": [
    "# transform the input/result data into the required scenario format\n",
    "\n",
    "from okareo_api_client.models.scenario_set_create import ScenarioSetCreate\n",
    "from okareo_api_client.models.seed_data import SeedData\n",
    "\n",
    "seed_data = []\n",
    "\n",
    "for key in inputs.keys():\n",
    "    input_ = inputs[key]\n",
    "    result = results[key]\n",
    "    func_name = list(result['ground_truth'][0].keys())[0]\n",
    "    func_args = {k: v[0] for k, v in result['ground_truth'][0][func_name].items() if len(v) > 0}\n",
    "    parsed_result = {\n",
    "        \"function\": {\n",
    "            \"name\": func_name,\n",
    "            \"arguments\": func_args,\n",
    "        }\n",
    "    }\n",
    "    seed_data.append(\n",
    "        SeedData(\n",
    "            input_ = {\n",
    "                \"question\": input_[\"question\"],\n",
    "                \"function\": input_[\"function\"]\n",
    "            },\n",
    "            result = parsed_result\n",
    "        )\n",
    "    )\n",
    "\n",
    "tool_scenario = okareo.create_scenario_set(\n",
    "    ScenarioSetCreate(\n",
    "        name=f\"BFCL Gorilla - Simple Function Call\",\n",
    "        seed_data=seed_data,\n",
    "    ) \n",
    ")\n",
    "\n",
    "print(tool_scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The name for a scenario must be unique. The scenario name BFCL Gorilla - Simple Function Call (10 rows) is already in use, and has been returned from this call.\n"
     ]
    }
   ],
   "source": [
    "tool_scenario_small = okareo.create_scenario_set(\n",
    "    ScenarioSetCreate(\n",
    "        name=f\"BFCL Gorilla - Simple Function Call (10 rows)\",\n",
    "        seed_data=seed_data[:10],\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_to_oai_types = {\n",
    "    \"str\": \"string\",\n",
    "    \"int\": \"integer\",\n",
    "    \"float\": \"number\",\n",
    "    \"bool\": \"boolean\",\n",
    "    \"list\": \"array\",\n",
    "    \"dict\": \"object\",\n",
    "}\n",
    "\n",
    "def parse_input_to_openai_tool(input_function):\n",
    "    # format the function call to be used in the OpenAI completion 'tools' arg\n",
    "    # see here: https://platform.openai.com/docs/guides/function-calling\n",
    "    tools = []\n",
    "    for tool in input_function:\n",
    "        params = tool[\"parameters\"]\n",
    "        tools.append({\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool[\"name\"],\n",
    "                \"description\": tool[\"description\"],\n",
    "                \"parameters\": {\n",
    "                    \"type\": py_to_oai_types[params[\"type\"]],\n",
    "                    \"properties\": params[\"properties\"],\n",
    "                    \"required\": params[\"required\"],\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_user_info',\n",
       "   'description': 'Retrieve details for a specific user by their unique identifier.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'user_id': {'type': 'integer',\n",
       "      'description': 'The unique identifier of the user. It is used to fetch the specific user details from the database.'},\n",
       "     'special': {'type': 'string',\n",
       "      'description': 'Any special information or parameters that need to be considered while fetching user details.',\n",
       "      'default': 'none'}},\n",
       "    'required': ['user_id']}}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed_data[0].input_['function']\n",
    "parse_input_to_openai_tool(seed_data[0].input_['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "import re\n",
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "class FunctionCallModel(CustomModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def invoke(self, input_value):\n",
    "        messages = input_value['question'][0]\n",
    "        tools = parse_input_to_openai_tool(input_value[\"function\"])\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        # extract the function call from the completion and return in invocation\n",
    "        completion_tool_calls = []\n",
    "        for tc in completion.choices[0].message.tool_calls:\n",
    "            parsed_tool = tc.to_dict()\n",
    "            parsed_tool['function']['arguments'] = json.loads(parsed_tool['function']['arguments'])\n",
    "            completion_tool_calls.append(parsed_tool)\n",
    "        out = {\"tool_calls\": completion_tool_calls} \n",
    "        return ModelInvocation(\n",
    "            model_input=messages,\n",
    "            tool_calls=out[\"tool_calls\"]\n",
    "        )\n",
    "\n",
    "# Register the model to use in the test run\n",
    "mut_name=\"GPT-4o Function Call Model\"\n",
    "model_under_test = okareo.register_model(\n",
    "    name=mut_name,\n",
    "    model=[FunctionCallModel(name=FunctionCallModel.__name__)],\n",
    "    update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation that uses the scenario, check, and model\n",
    "from okareo_api_client.models.test_run_type import TestRunType\n",
    "\n",
    "eval_name = f\"BFCL Gorilla - Simple Function Call Evaluation\"\n",
    "evaluation = model_under_test.run_test(\n",
    "    name=eval_name,\n",
    "    scenario=tool_scenario_small.scenario_id,\n",
    "    test_run_type=TestRunType.NL_GENERATION,\n",
    "    checks=[\"function_call_validator\",\n",
    "            \"is_function_correct\",\n",
    "            \"are_all_params_expected\",\n",
    "            \"are_required_params_present\",\n",
    "            \"do_param_values_match\"]\n",
    ")\n",
    "print(f\"See results in Okareo: {evaluation.app_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
